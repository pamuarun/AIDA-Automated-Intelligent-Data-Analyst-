# ü§ñ AI Data Analyst Assistant

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.51.0-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-GNU-green.svg)](LICENSE)

An intelligent data analysis platform that automates exploratory data analysis, data cleaning, and generates actionable insights using AI-powered agents. Built with Python, Streamlit, and Google's Gemini AI.

## üìã Table of Contents
- [Project Summary](#project-summary)
- [Introduction](#introduction)
- [Features](#features)
- [Technology Stack](#technology-stack)
- [Agents Overview](#agents-overview)
- [Memory System](#memory-system)
- [Utilities](#utilities)
- [Use Cases](#use-cases)
- [Security](#security)
- [Support](#support)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [License](#license)

## üìä Project Summary

The AI Data Analyst Assistant is a comprehensive data analysis platform that automates the entire data science workflow from raw data to actionable insights. Leveraging a multi-agent architecture powered by Google's Gemini AI, this tool performs exploratory data analysis, cleans datasets, generates visualizations, and produces detailed reports - all through an intuitive web interface.

## üöÄ Introduction

Data analysis is a critical but time-consuming process that requires expertise in statistics, programming, and domain knowledge. The AI Data Analyst Assistant democratizes data science by providing an automated solution that handles the technical complexities while delivering professional-grade analysis. Whether you're a data scientist, business analyst, or researcher, this tool accelerates your workflow by automating repetitive tasks and providing AI-powered insights.

The platform features a beautiful dark-themed interface with animated elements, interactive visualizations, and a chatbot interface for asking questions about your data. It supports both CSV and Excel file formats and provides comprehensive data preprocessing capabilities.

## ‚ú® Features

### Data Analysis & Exploration
- **Automated EDA**: Comprehensive exploratory data analysis with statistical summaries
- **Visualizations**: Distribution plots, correlation heatmaps, boxplots, and more
- **Statistical Insights**: Skewness, kurtosis, outlier detection, and correlation analysis
- **Data Profiling**: Automatic detection of data types, missing values, and duplicates

### Data Cleaning & Preprocessing
- **Missing Value Imputation**: Intelligent imputation using mean, median, or mode
- **Outlier Handling**: Winsorization technique for outlier treatment
- **Duplicate Removal**: Automatic detection and removal of duplicate records
- **Low Variance Filtering**: Removal of columns with minimal variance

### AI-Powered Insights
- **Gemini AI Integration**: Leverages Google's Gemini 2.0 Flash for intelligent analysis
- **Executive Summaries**: High-level business insights generated by AI
- **Anomaly Detection**: AI-powered identification of data anomalies
- **Recommendations**: Actionable recommendations for further analysis

### Reporting & Visualization
- **Interactive Dashboard**: Real-time KPI cards and data summaries
- **Chat Interface**: Ask questions about your data and get AI-powered responses
- **Visualization Gallery**: Comprehensive collection of data visualizations

### User Experience
- **Modern UI**: Beautiful dark-themed interface with animations and floating effects
- **Responsive Design**: Works on desktop and tablet devices
- **Real-time Feedback**: Progress indicators and loading states
- **Intuitive Navigation**: Clean and organized interface

## üõ†Ô∏è Technology Stack

### Core Technologies
- **Python 3.12**: Primary programming language
- **Streamlit**: Web framework for creating interactive dashboards
- **Pandas**: Data manipulation and analysis
- **NumPy**: Numerical computing
- **Matplotlib & Seaborn**: Data visualization libraries

### AI & Machine Learning
- **Google Generative AI**: Gemini 2.0 Flash for AI-powered insights
- **LangChain**: Framework for developing applications with LLMs
- **Feature Engine**: Feature engineering and data preprocessing

### Utilities & Tools
- **dotenv**: Environment variable management
- **SciPy**: Scientific computing and statistics

### Frontend Enhancements
- **HTML/CSS**: Custom styling and animations
- **JavaScript**: Interactive elements (through Streamlit)

## ü§ñ Agents Overview

### 1. Orchestrator Agent
The central coordinator that manages the entire data analysis pipeline:
- Initializes and coordinates all specialized agents
- Manages data flow between agents
- Stores results in memory for later retrieval
- Handles chatbot queries

### 2. EDA Agent (Exploratory Data Analysis)
Performs comprehensive data analysis:
- Generates statistical summaries (mean, median, std, etc.)
- Calculates skewness and kurtosis for numeric columns
- Detects outliers using IQR method
- Creates correlation matrices
- Generates distribution plots and correlation heatmaps

### 3. Cleaning Agent
Handles data preprocessing tasks:
- Removes duplicate records
- Imputes missing values using appropriate methods (mean/median for numeric, mode for categorical)
- Removes low-variance columns
- Applies Winsorization for outlier treatment
- Generates before/after comparison visualizations

### 4. Insights Agent
Provides AI-powered analysis using Google's Gemini:
- Generates executive summaries
- Identifies data anomalies
- Finds top correlations
- Provides business impact analysis
- Answers user questions through chat interface

## üß† Memory System

### Session Memory
Manages temporary data storage during user sessions:
- Stores EDA results and visualizations
- Maintains cleaned datasets
- Keeps track of chat history
- Manages intermediate processing results

### Long Term Memory
Handles persistent data storage:
- Stores user preferences and settings
- Maintains historical analysis results
- Keeps record of frequently used queries
- Manages template configurations

## üõ†Ô∏è Utilities

### Plot Utilities
Helper functions for creating visualizations:
- `fig_to_png_bytes()`: Converts matplotlib figures to PNG byte streams
- `distribution_plot()`: Creates distribution plots with KDE
- `box_plot()`: Generates box plots for outlier visualization
- `correlation_heatmap()`: Creates correlation matrix heatmaps

### File Utilities
Functions for file handling and processing:
- Dataset loading and validation
- File format detection (CSV, Excel)
- Temporary file management
- Path resolution utilities

### Chatbot Parser
Processes and manages chat interactions:
- Natural language query parsing
- Response formatting
- Context management
- Follow-up question handling

## üéØ Use Cases

### Business Analytics
- **Market Research**: Analyze customer behavior patterns and market trends
- **Sales Performance**: Identify top-performing products and seasonal trends
- **Financial Analysis**: Detect anomalies in financial data and forecast trends

### Academic Research
- **Data Cleaning**: Preprocess research datasets for analysis
- **Statistical Analysis**: Generate descriptive statistics for research papers
- **Visualization**: Create publication-ready charts and graphs

### Healthcare
- **Patient Data Analysis**: Identify patterns in patient records and treatment outcomes
- **Clinical Trials**: Analyze trial data for efficacy and safety
- **Epidemiology**: Track disease patterns and outbreak analysis

### E-commerce
- **Customer Segmentation**: Analyze customer demographics and purchasing behavior
- **Inventory Management**: Predict demand patterns and optimize stock levels
- **Pricing Strategy**: Analyze competitor pricing and market positioning

### Human Resources
- **Employee Performance**: Analyze performance metrics and identify improvement areas
- **Recruitment Analytics**: Track hiring metrics and optimize recruitment processes
- **Retention Analysis**: Identify factors affecting employee turnover

## üõ°Ô∏è Security

### Data Privacy
- **Local Processing**: All data processing happens locally on your machine
- **No Data Storage**: No user data is stored on external servers
- **Ephemeral Sessions**: Data is cleared when the session ends

### API Security
- **Environment Variables**: API keys are stored securely in environment variables
- **Encrypted Connections**: All API communications use HTTPS encryption
- **Key Rotation**: Regular rotation of API keys recommended
- **No external data transfer**
- **Safe session management**



### Access Control
- **Single User**: Designed for individual use with no multi-user access
- **Local Deployment**: Runs locally, eliminating network-based attacks
- **File System Permissions**: Respects OS-level file permissions

### Best Practices
- **Regular Updates**: Keep all dependencies updated to latest secure versions
- **Input Validation**: All file uploads are validated for type and size
- **Error Handling**: Secure error handling that doesn't expose sensitive information

## üÜò Support

### Documentation
- **This README**: Comprehensive project documentation
- **Code Comments**: Detailed comments in source code files
- **Inline Help**: Tooltips and guidance within the application

### Updates & Maintenance
- **Version Tracking**: Keep track of releases and updates
- **Migration Guides**: Instructions for upgrading between versions
- **Deprecation Notices**: Advance notice of feature removals

## üì¶ Installation

### Prerequisites
- Python 3.12 or higher
- pip package manager
- Google API Key for Gemini AI (free tier available)

### Setup Instructions

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd Capstone-Project
   ```

2. **Create a virtual environment**:
   ```bash
   python -m venv cap_env
   source cap_env/bin/activate  # On Windows: cap_env\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**:
   Create a `.env` file in the project root with your Google API key:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   ```

5. **Run the application**:
   ```bash
   streamlit run app.py
   ```

## üéØ Usage

1. **Start the Application**:
   Run `streamlit run app.py` and open the provided URL in your browser

2. **Upload Your Dataset**:
   - Click on the "Upload Dataset" section
   - Select a CSV or Excel file
   - Wait for automatic processing and analysis

3. **Explore the Dashboard**:
   - View dataset overview with KPI cards
   - Analyze data types and structures
   - Examine numeric EDA insights
   - Review data cleaning results

4. **Interact with Visualizations**:
   - View distribution plots for numeric columns
   - Analyze correlation heatmaps
   - Compare boxplots before and after cleaning
   - Explore categorical distributions

5. **Ask Questions**:
   - Use the chat interface to ask questions about your data
   - Get AI-powered insights and explanations
   - Request specific analyses or visualizations

## üìÅ Project Structure

```
Capstone-Project/
‚îú‚îÄ‚îÄ agents/                    # AI agents for data processing
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py        # Central coordinator
‚îÇ   ‚îú‚îÄ‚îÄ eda_agent.py           # Exploratory data analysis
‚îÇ   ‚îú‚îÄ‚îÄ cleaning_agent.py      # Data cleaning operations
‚îÇ   ‚îú‚îÄ‚îÄ insights_agent.py      # AI-powered insights
‚îÇ   ‚îî‚îÄ‚îÄ memory/                # Memory management
‚îÇ       ‚îú‚îÄ‚îÄ session_memory.py
‚îÇ       ‚îî‚îÄ‚îÄ long_term_memory.py
‚îú‚îÄ‚îÄ utils/                     # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ plot_utils.py          # Visualization helpers
‚îÇ   ‚îú‚îÄ‚îÄ file_utils.py          # File handling utilities
‚îÇ   ‚îî‚îÄ‚îÄ chatbot_parser.py      # Chatbot parsing utilities
‚îú‚îÄ‚îÄ outputs/                   # Generated outputs
‚îÇ   ‚îî‚îÄ‚îÄ visualizations/        # Saved visualizations
‚îú‚îÄ‚îÄ app.py                     # Main Streamlit application
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ .env                       # Environment variables
‚îî‚îÄ‚îÄ README.md                  # Project documentation
```

## üîÆ Future Improvements

### Short-term Enhancements
1. **Advanced ML Models**:
   - Integration of predictive modeling capabilities
   - Automated model selection and evaluation
   - Feature importance analysis

2. **Enhanced Visualization**:
   - Interactive Plotly charts
   - 3D visualizations for complex data
   - Custom visualization builder

3. **Expanded Data Sources**:
   - Database connectivity (SQL, NoSQL)
   - API data ingestion
   - Cloud storage integration (AWS S3, Google Cloud)

4. **Improved AI Capabilities**:
   - Multi-language support
   - Enhanced natural language processing
   - Custom prompt engineering for domain-specific analysis

### Long-term Vision
1. **Collaboration Features**:
   - Team sharing and collaboration
   - Commenting and annotation system
   - Version control for analyses

2. **Deployment Options**:
   - Docker containerization
   - Cloud deployment scripts
   - Kubernetes orchestration

3. **Advanced Analytics**:
   - Time series analysis
   - Geospatial data processing
   - Text analytics and NLP

4. **Enterprise Features**:
   - User authentication and authorization
   - Audit trails and compliance
   - Custom branding and theming


## üìÑ License

This project is licensed under the GNU License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Google Generative AI team for the Gemini API
- Streamlit team for the excellent web framework
- Open source community for the various libraries used
- All contributors who have helped shape this project

---

*Transforming Data Chaos Into Clarity*

